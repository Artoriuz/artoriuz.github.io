<!DOCTYPE html>
<html lang="en">

<head>
    <title>Evaluating mpv's upscaling algorithms - A study of performance and quality</title>
    <meta charset="utf-8" />
    <link rel="stylesheet" type="text/css" href="./css/default.css" />
    <link rel="stylesheet" type="text/css" href="./css/syntax.css" />
    <script src="https://cdn.rawgit.com/google/code-prettify/master/loader/run_prettify.js?skin=doxy"></script>
</head>

<body>
    <header>
        <hgroup>
            <h1>
                <a href="./index.html">Evaluating mpv's upscaling algorithms</a>
            </h1>
            <h2>A study of performance and quality by João Vitor Chrisóstomo</h2>
        </hgroup>
    </header>
    <nav>
        <menu>
            <a href="./index.html">Home</a>
            <a href="https://github.com/artoriuz">GitHub</a>
            <!--<a href="./index_pt.html">Versão em português</a>-->
        </menu>
    </nav>
    <section>
        <h3 id="introduction">Introduction</h3>
        <p>
            This work aims to mathematically quantify image quality and performance of different real-time upscaling algorithms.
        </p>
        <p>
            Before attempting to reproduce, make sure to grab the latest version of <a href="https://mpv.io/">mpv</a> and updated user shaders. You can get 
            the shaders from <a href="https://github.com/bjin/mpv-prescalers">bjin</a> and <a href="https://github.com/igv/FSRCNN-TensorFlow/releases">igv (FSRCNNX)</a>/<a href="https://gist.github.com/igv">igv (SSSR)</a>.
        </p>
        <p>
            UPDATE - 15/02/2018: Other EWA scalers were added.
        </p>
        <p>
            UPDATE - 22/12/2018: I found out a mistake in previous results, and have once again updated all quality comparison results.
            <br>
            I'm not certain about what was causing the problems, but turning off PNG filtering and debanding seems to have fixed it. I'll investigate which of the two was the culprit once I have the time. 
            <br>
            Well, since I had to redo everything, I took this opportunity to improve the testing methodology, debanding was turned off to prevent loss of detail, and I used a lossless 
            YUV444P AVC encode as upscaling source instead of a YUV444P JPEG.  
        </p>
        <p>
            UPDATE - 18/12/2018: Results have been updated with latest versions of FSRCNNX and Waifu2x. On top of that, I've included MS-SSIM and PSNR-HVS-M measurements. 
            I've also included all NGU algorithms from <a href="http://madvr.com/">MadVR</a> since people are interested on them, though NGU-AA performs poorly due to half-pixel shifts.  
        </p>
        <p>
            If all you want is to look at the results, <a href=#results>follow this link.</a> 
        </p>
        <h3 id="upscaling">What is upscaling?</h3>
        <p>
            Like its name implies, upscaling is simply increasing the scale of something. More specifically, taking discrete information
            in a given scale and finding values between the existing samples. The easiest and most classic way of doing this
            is through simple linear interpolation, if you want to find a value between two points you can simply draw a
            line between them and linearly find any value in this line. If you wanted to find the value that's placed exactly
            in the middle of those 2 discrete points, you could simply do an arithmetic mean with their values to find your
            answer.
        </p>
        <p>
            Linear interpolation can be done in a plane, through both axis, creating what we call "bilinear" interpolation. Bilinear
            interpolation is the simplest interpolation algorithm, easiest to calculate and also unironically the most used
            one in the industry due to the fact that it's extremely simple to implement.
        </p>
        <p>
            But can something as simple as just drawing a line between 2 known discrete points give us good results? It depends entirely
            on how the original information looked like. We can however, increase the complexity of our upscaling algorithm
            by increase the amount of information it takes into consideration in order to find values between our discrete
            points. In this page we'll evaluate what we can do differently, how much better our results can get and how it
            affects our performance.
        </p>
        <h3 id="polynomial">Polynomial interpolation</h3>
        <p>
            <img src="./images/mpv_upscaling/interpolation.png" alt="upscaling" class="center">
            <br>
            A relatively simple way of taking more information into consideration when finding values between discrete points is to use
            more than just the information of 2 points to calculate a function that connects them. We can trace a polynomial
            curve between points if we take into account the information of neighbouring elements, calculating the gradients
            and therefore becoming able to connect them with curves instead of lines. The shape of the curve connecting points
            depends on the windowing and scaling functions used.
        </p>
        <h3 id="SSSR">Structural Similarity Upscaling</h3>
        <img src="./images/mpv_upscaling/sssr_bilinear.png" alt="upscaling" class="center">
        <br>
        <img src="./images/mpv_upscaling/sssr_sssr.png" alt="upscaling" class="center">
        <p>
            We can more precisely upscale something if we try to reconstruct strucutures, the most evident problem with linear or polynomial
            scalers is the thickening of border areas where the interpolated result doesn't transit between values as sharply,
            resulting in a blurrier image with "lost" detail in the strucutures if you're downscaling and then upscaling
            it back.
        </p>
        <h3 id="neural">Convolutional Neural Networks</h3>
        <p>
            Another way of trying to "recover" lost information through upscaling is using neural networks that firstly go through a
            training phase so it can "learn" how to upscale. The training phase consists of analysing a set of images, and
            then setting parameters that will be used when upscaling. Note that upscaling isn't exactly recovering information, 
            all we're doing is coming up with "new" information based on what we already have.
        </p>
        <p>
            There are multiple different ways of using neural networks to upscale images, and there are multiple different algorithms
            that aim to do pretty much the same thing. To make it more practical, we'll stick to algorithms that can be easily
            tested as user-shaders using mpv, with the adition of the extremely popular Waifu2X and NGU from MadVR. 
        </p>
        <p>
            We'll test the following algorithms:
            <li><a href="https://github.com/bjin/mpv-prescalers">RAVU</a></li>
            <li><a href="http://avisynth.nl/index.php/Nnedi3">NNEDI3</a></li>
            <li><a href="https://github.com/igv/FSRCNN-TensorFlow">FSRCNNX</a></li>
            <li><a href = "http://madvr.com/">NGU(AA/SOFT/STANDARD/SHARP)</a></li>
            <li><a href="https://github.com/nagadomi/waifu2x">Waifu2x</a></li>
        </p>
        
        <h3 id="methodology">Testing methodology</h3>
        <p>
            Performance measurements were done upscaling an animation video encoded into 8bit AVC from 1280x720 to 2560x1440. Utilising mpv
            with a benchmarking profile, all settings from profile=gpu-hq, fixing scalers
            that do half-pixel shifts (with the exception of NGU-AA, since as far as I know there's no option to fix it in MadVR), 
            with Vulkan as the renderer and hardware decoding turned off. The machine used has
            an Ivy Bridge i5 3470, a Polaris RX 470 and user shaders were always compute shaders when possible.
        </p>
        <p>
            Quality measurements were done in 2 test images, one from animation and another one from live action. Debanding was turned off to prevent loss of fine detail, and so was 
            mpv's PNG screenshot filtering. 
        </p>
        <p>
            The reasoning behind this comes from the fact that the live action image has more high frequency components that are harder
            to "restore". In order to measure how "good" each algorithm is, the test images were previously bicubic downscaled
            to a quarter of their original resolutions (0.5x scaling factor in both axes), and then upscaled back to their
            original resolutions with a direct 2x upscaling factor (2x in both axes outputs a resolution that's 4x larger in pixels). 
            Every single scaler was tested on an YUV444P lossless AVC encode, which can be found on the repository. 
        </p>
        <p>
            Performance was evaluated simply in frames per second, while quality was evaluated in 
            <a href="https://en.wikipedia.org/wiki/Peak_signal-to-noise_ratio">PSNR</a>, 
            <a href="https://en.wikipedia.org/wiki/Structural_similarity">SSIM</a>, 
            <a href="http://mrim.imag.fr/yubing.tong/Files_YubingTong/JIST4516-Accepted.pdf">PSNR-HVS-M</a> and 
            <a href="https://ece.uwaterloo.ca/~z70wang/publications/msssim.html">MS-SSIM</a>.
        </p>
        
        
        <h3 id="results">Testing and results</h3>
        <p>The following image was used for the animation upscaling testing:</p>
        <img src="./images/mpv_upscaling/violet/downscaled.png" alt="Downscaled Violet" class="center">
        <br>
        <p>
            Before we continue to the results, you can find all images in <a href="https://github.com/Artoriuz/artoriuz.github.io/tree/master/images/mpv_upscaling/violet">this repository.</a>
        </p>
        <p>We can see the results below:</p>
        <div class="row">
            <div class="column">
                <img src="./images/mpv_upscaling/tables/fps.png" alt="Violet results FPS" width="454" height="756">
            </div>
            <div class="column">
                <img src="./images/mpv_upscaling/tables/violet-ssim.png" alt="Violet results SSIM" width="454" height="756">
            </div>
            <div class="column">
                <img src="./images/mpv_upscaling/tables/violet-psnr.png" alt="Violet results PSNR" width="454" height="756">
            </div>
            <div class="column">
                <img src="./images/mpv_upscaling/tables/violet-msssim.png" alt="Violet results MS-SSIM" width="454" height="756">
            </div>
            <div class="column">
                <img src="./images/mpv_upscaling/tables/violet-psnrhvsm.png" alt="Violet results PSNR-HVS-M" width="454" height="756">
            </div>
          </div>
    
        <!--
        <p>Or in a table format, for those who prefer to just look at the numbers:</p>
        <div w3-include-html="./html/violet.htm"></div>
        -->
        
        <p>The following image was used for the live-action upscaling testing:</p>
        <img src="./images/mpv_upscaling/shuri/downscaled.png" alt="Downscaled Shuri" class="center">
        <br>
        <p>
            Again, you can find all the images in <a href="https://github.com/Artoriuz/artoriuz.github.io/tree/master/images/mpv_upscaling/shuri">this repository.</a>
        </p>
        <p>We can see the results below:</p>
        <div class="row">
            <div class="column">
                <img src="./images/mpv_upscaling/tables/fps.png" alt="shuri results FPS" width="454" height="756">
            </div>
            <div class="column">
                <img src="./images/mpv_upscaling/tables/shuri-ssim.png" alt="shuri results SSIM" width="454" height="756">
            </div>
            <div class="column">
                <img src="./images/mpv_upscaling/tables/shuri-psnr.png" alt="shuri results PSNR" width="454" height="756">
            </div>
            <div class="column">
                <img src="./images/mpv_upscaling/tables/shuri-msssim.png" alt="shuri results MS-SSIM" width="454" height="756">
            </div>
            <div class="column">
                <img src="./images/mpv_upscaling/tables/shuri-psnrhvsm.png" alt="shuri results PSNR-HVS-M" width="454" height="756">
            </div>
          </div>
       
         <!--
        <p>And again, a table:</p>
        <div w3-include-html="./html/shuri.htm"></div>
        -->

        <p>
            We can clearly see that in general, neural network based scalers tend to give better quality, though they're also more computationally
            expensive. We can see that FSRCNNX is clearly the best scaler you can use on mpv when it comes to quality, and NGU from MadVR performs very similarly, though FSRCNNX seems to 
            have an edge.  
        </p>
        <p>
            All NGU algorithms were tested on their highest quality presets (Very High), which was still fine on the RX470 but way more computationally expensive than FSRCNNX-8-0-4-1. 
            Performance of FSRCNNX-16-0-4-1 is also relatively okay, but the quality difference over its lighter variant is small. FSRCNNX-56-16-4-1 and FSRCNNX-GAN-FORSCIENCE-56-16-4-1 
            are not worth it. 
        </p>
        <p>
            NNEDI3, Ravu and SSSR are mostly pointless, FSRCNNX-8-0-4-1 is better and performs extremely well. 
        </p>
        <p>
            If you're using MadVR, I think both NGU-STANDARD and NGU-SHARP look awesome as long as your system can handle them, and you can choose whichever you like the most.
        </p>
    </section>


    <footer>

    </footer>
</body>
<script>
    function includeHTML() {
        var z, i, elmnt, file, xhttp;
        /*loop through a collection of all HTML elements:*/
        z = document.getElementsByTagName("*");
        for (i = 0; i < z.length; i++) {
            elmnt = z[i];
            /*search for elements with a certain atrribute:*/
            file = elmnt.getAttribute("w3-include-html");
            if (file) {
                /*make an HTTP request using the attribute value as the file name:*/
                xhttp = new XMLHttpRequest();
                xhttp.onreadystatechange = function () {
                    if (this.readyState == 4) {
                        if (this.status == 200) { elmnt.innerHTML = this.responseText; }
                        if (this.status == 404) { elmnt.innerHTML = "Page not found."; }
                        /*remove the attribute, and call this function once more:*/
                        elmnt.removeAttribute("w3-include-html");
                        includeHTML();
                    }
                }
                xhttp.open("GET", file, true);
                xhttp.send();
                /*exit the function:*/
                return;
            }
        }
    }
</script>
 <script>
        includeHTML();
</script> 
</html>
